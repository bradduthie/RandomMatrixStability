---
title: "Component response rate variation drives stability in large complex systems"
author: "A. Bradley Duthie    ( alexander.duthie@stir.ac.uk )"
date: Biological and Environmental Sciences, University of Stirling, Stirling, UK,
  FK9 4LA
output:
  word_document:
    fig_caption: yes
    pandoc_args:
    - --csl
    - science.csl
    reference_docx: docx_template.docx
  pdf_document:
    fig_caption: yes
    keep_tex: no
  html_document: default
bibliography: references.bib
header-includes:
- \usepackage{amsmath}
- \usepackage{natbib}
- \usepackage{lineno}
- \usepackage[utf8]{inputenc}
- \linenumbers
- \bibliographystyle{amnatnat}
linestretch: 2
link-citations: no
linkcolor: blue
csl: science.csl
biblio-style: apalike
---

<!---
Abstract current word count: 225
Text current word count: 1453
--->

<!---
"This will generate the intermediate files that are actually used to generate the PDF. You need only go to the directory where your .Rmd file is, gather the .tex and image directory (called filename_files) with"

arxiv comand: tar cvfz filename.tgz filename.tex filename_files

https://gist.github.com/JJ/ef9d3d8f1142df064bd5
--->

```{r, echo = FALSE}
source(file = "R_old/sim_mat.R");
source(file = "R_old/plot_figs.R");
```



**The stability of a complex system generally decreases with increasing system size and interconnectivity, a counter-intuitive result of widespread importance across the physical, life, and social sciences. Despite recent interest in the relationship between system properties and stability, the effect of variation in the response rate of individual system components remains unconsidered. Here I vary the component response rates ($\boldsymbol{\gamma}$) of randomly generated complex systems. I show that when component response rates vary, the potential for system stability is markedly increased. Variation in $\boldsymbol{\gamma}$ becomes increasingly important as system size increases, such that the largest stable complex systems would be unstable if not for $\boldsymbol{Var(\gamma)}$. My results reveal a previously unconsidered driver of system stability that is likely to be pervasive across all complex systems.**

<!---

**The stability of a complex system generally decreases with increasing system size, as is demonstrated by random matrix theory [@May1972; @Allesina2012]. This counter-intuitive result, first shown by May [@May1972], is broadly relevant for understanding the dynamics and persistence of systems such as ecological [@May1972; @Allesina2012], neurological [@Gray2008; @Gray2009], biochemical [@Rosenfeld2009; @MacArthur2010] and socio-economic [@Haldane2011; @Suweis2014; @Bardoscia2017] networks. Much attention has especially been given to the stability of ecological communities such as food webs or mutualist networks, with recent work investigating how different community structures affect stability [@Allesina2012; @Mougi2012; @Allesina2015a; @Gao2016; @Grilli2017; @Patel2018]. But more broadly, stabilising mechanisms in complex systems remain under-developed, and the effect of variation in the response rate of individual system components remains an open problem [@Allesina2015]. Here I show that when components of a complex system respond to system perturbation at different rates ($\boldsymbol{\gamma}$), the potential for system stability is markedly increased. Stability is caused by the clustering of some eigenvalues toward the centre of eigenvalue distributions despite the destabilising effect of higher interaction strength variation ($\boldsymbol{\sigma^{2}}$). This effect of variation in $\boldsymbol{\gamma}$ becomes increasingly important as system size increases, to the extent that the largest stable complex systems would otherwise be unstable if not for $\boldsymbol{Var(\gamma)}$. My results therefore reveal a previously unconsidered driver of system stability that is likely to be pervasive across all complex systems. Future research in complex systems should therefore account for the varying response rates of individual system components when assessing whole system stability.** 

--->

In 1972, May [@May1972] first demonstrated that randomly assembled systems of sufficient complexity are almost inevitably unstable given infinitesimally small perturbations. Complexity in this case is defined by the size of the system (i.e., the number of potentially interacting components; $S$), its connectance (i.e., the probability that one component will interact with another; $C$), and the variance of interaction strengths ($\sigma^{2}$) [@Allesina2012]. May's finding that the probability of local stability falls to near zero given a sufficiently high threshold of $\sigma\sqrt{SC}$ is broadly relevant for understanding the dynamics and persistence of systems such as ecological [@May1972; @Allesina2012; @Mougi2012; @Allesina2015; @Grilli2017], neurological [@Gray2008; @Gray2009], biochemical [@Rosenfeld2009; @MacArthur2010], and socio-economic [e.g., banking; @May2008; @Haldane2011; @Suweis2014; @Bardoscia2017] networks. As such, identifying general principles that drive stability in complex systems is of wide-ranging importance.


Randomly assembled complex systems can be represented as large square matrices ($M$) with $S$ components (e.g., networks of species [@Allesina2012] or banks [@Haldane2011]). One element of such a matrix, $M_{ij}$, defines how component $j$ affects component $i$ in the system at a point of equilibrium [@Allesina2012]. Off-diagonal elements ($i \neq j$) therefore define interactions between components, while diagonal elements ($i = j$) define component self-regulation (e.g., carrying capacity in ecological communities). Traditionally, off-diagonal elements are assigned non-zero values with a probability $C$, which are sampled from a distribution with variance $\sigma^{2}$; diagonal elements are set to -1 [@May1972; @Allesina2012; @Allesina2015]. Local system stability is assessed using eigenanalysis, with the system being stable if the real parts of all eigenvalues ($\lambda$) of $M$ are negative ($\max\left(\Re(\lambda)\right) < 0$) [@May1972; @Allesina2012]. In a large system (high $S$), eigenvalues are distributed uniformly [@Tao2010] within a circle centred at $\Re = -1$ (the mean value of diagonal elements) and $\Im = 0$, with a radius of $\sigma\sqrt{SC}$ [@May1972; @Allesina2012; @Allesina2015] (Figs 1a and 2a). Local stability of randomly assembled systems therefore becomes increasingly unlikely as $S$, $C$, and $\sigma^{2}$ increase.

May's [@May1972; @Allesina2012] stability criterion $\sigma\sqrt{SC} < 1$ assumes that individual components respond to perturbations of the system at the same rate ($\gamma$), but this is highly unlikely in any complex system. In ecological communities, for example, the rate at which population density changes following perturbation will depend on the generation time of individuals, which might vary by orders of magnitude among species. Species with short generation times will respond quickly (high $\gamma$) to perturbations relative to species with long generation times (low $\gamma$). Similarly, the speed at which individual banks respond to perturbations in financial networks, or individuals or institutions respond to perturbations in complex social networks, is likely to vary. The effect of such variance has not been investigated in complex systems theory. Intuitively, variation in $\gamma$ might be expected to decrease system stability by introducing a new source of variation into the system and thereby increasing $\sigma$. Here I show why, despite higher $\sigma$, complex systems in which $\gamma$ varies are actually more likely to be stable, especially when $S$ is high.  

<!---

Introduction could end here.

--->

```{r echo = FALSE}
S     <- 200;
C     <- 0.05;
sigma <- 0.4;
pr_st <- read.csv(file = "sim_results/bi_gamma/bi_pr_st.csv");
pr_st <- pr_st[,-1];
```


```{r, echo = FALSE}
A0 <- read.csv(file = "sim_results/bi_gamma/S200_A0.csv");
A0 <- as.matrix(A0[,-1]);
A1 <- read.csv(file = "sim_results/bi_gamma/S200_A1.csv");
A1 <- as.matrix(A1[,-1]);

A0_e   <- eigen(A0)$values;
A0_r   <- Re(A0_e);
A0_i   <- Im(A0_e);
A1_e   <- eigen(A1)$values;
A1_r   <- Re(A1_e);
A1_i   <- Im(A1_e);

A0_vm       <- A0;
diag(A0_vm) <- NA;
A0vec       <- as.vector(t(A0_vm));
A0vec       <- A0vec[is.na(A0vec) == FALSE];
A1_vm       <- A1;
diag(A1_vm) <- NA;
A1vec       <- as.vector(t(A1_vm));
A1vec       <- A1vec[is.na(A1vec) == FALSE];
fhalf       <- 1:(0.5*length(A1vec));
shalf       <- (0.5*length(A1vec)+1):length(A1vec);
pr_st       <- read.csv(file = "sim_results/bi_gamma/bi_pr_st.csv");
pr_st       <- pr_st[,-1];
```



Rows in $M$ define how a given component $i$ is affected by other components of the system, meaning that the rate of component response time can be modelled by multiplying all row elements by a real scalar value $\gamma_{i}$ [@Patel2018] (see Supplementary Information for details). The distribution of $\gamma$ over $S$ components thereby models the distribution of component response rates. An instructive example compares one $M$ where $\gamma_{i} = 1$ for all $i$ in $S$ to the same $M$ when half of $\gamma_{i} = 1.95$ and half of $\gamma_{i} = 0.05$. This models one system in which $\gamma$ is invariant and one in which $\gamma$ varies, but systems are otherwise identical (note $E[\gamma_{i}] = 1$ in both cases). I assume $S = 200$, $C = 0.05$, and $\sigma = 0.4$; diagonal elements are set to $-1$ and non-zero off-diagonal elements are drawn randomly from $\mathcal{N}(0, \sigma^{2})$. Rows are then multiplied by $\gamma_{i}$ to generate $M$. When $\gamma_{i} = 1$, eigenvalues of $M$ are distributed uniformly within a circle centred at ($-1, 0$) with a radius of `r round(sigma*sqrt(S*C), digits = 3)` (Fig. 1a). Hence, the real components of eigenvalues are highly unlikely to all be negative when all $\gamma_{i} = 1$. But when $\gamma_{i}$ values are separated into two groups, eigenvalues are no longer uniformly distributed (Fig. 1b). Instead, two distinct clusters of eigenvalues appear (grey circles in Fig. 1b), one centred at ($-1.95, 0$) and the other centred at ($-0.05, 0$). The former has a large radius, but the real components have shifted to the left (in comparison to when $\gamma = 1$) and all $\Re({\lambda}) < 0$. The latter cluster has real components that have shifted to the right, but has a smaller radius. Overall, for 1 million randomly assembled $M$, this division between slow and fast component response rates results in more stable systems: `r sum(pr_st[,1])` stable given $\gamma = 1$ versus `r sum(pr_st[,2])` stable given $\gamma = \{1.95, 0.5\}$.

```{r echo = FALSE}
S     <- 1000;
C     <- 0.05;
sigma <- 0.4;
```


```{r, echo = FALSE}
A_comp <- NULL;
A_dat  <- rnorm(n = 1000000, mean = 0, sd = 0.4);
A_mat  <- matrix(data = A_dat, nrow = 1000);
C_dat  <- rbinom(n = 1000 * 1000, size = 1, prob = 0.05);
C_mat  <- matrix(data = C_dat, nrow = 1000, ncol = 1000);
A_mat     <- A_mat * C_mat;
A_mat  <- species_interactions(A_mat, type = 0);
gammas <- c(rep(0.05, 500), rep(1.95, 500));

mu_gam <- mean(gammas);
diag(A_mat) <- -1;
A1     <- gammas * A_mat;
A0     <- mu_gam * A_mat;
A0_e   <- eigen(A0)$values;
A0_r   <- Re(A0_e);
A0_i   <- Im(A0_e);
A1_e   <- eigen(A1)$values;
A1_r   <- Re(A1_e);
A1_i   <- Im(A1_e);

A0_vm       <- A0;
diag(A0_vm) <- NA;
A0vec       <- as.vector(A0_vm);
A0vec       <- A0vec[is.na(A0vec) == FALSE];
A1_vm       <- A1;
diag(A1_vm) <- NA;
A1vec       <- as.vector(A1_vm[1:500,]);
A1vec       <- A1vec[is.na(A1vec) == FALSE];
```

Higher stability in systems with variation in $\gamma$ can be observed by sampling $\gamma_{i}$ values from various distributions. I now focus on a uniform distribution where $\gamma \sim \mathcal{U}(0, 2)$ (see Supplementary Information for other distributions, which give similar results). As with the case of $\gamma = \{1.95, 0.5\}$ (Fig. 1b), $E[\gamma] = 1$ when $\gamma \sim \mathcal{U}(0, 2)$, allowing comparison of $M$ before and after variation in component response rate. Figure 2 shows a comparison of eigenvalue distributions given $S = 1000$, $C = 0.05$, and $\sigma = 0.4$. As expected [@Tao2010], when $\gamma = 1$, eigenvalues are distributed uniformly in a circle centred at ($-1, 0$) with a radius of $\sigma\sqrt{SC} =$ `r round(sigma*sqrt(S*C), digits = 3)`. Uniform variation in $\gamma$ leads to a non-uniform distribution of eigenvalues, some of which are clustered locally near the centre of the distribution, but others of which are spread outside the former radius of `r round(sigma*sqrt(S*C), digits = 3)` (Fig 2b). The clustering and spreading of eigenvalues introduced by $Var(\gamma)$ can destabilise previously stable systems or stabilise systems that are otherwise unstable. But where systems are otherwise too complex to be stable given $\gamma = 1$, the effect of $Var(\gamma)$ can often lead to stability above May's [@May1972; @Allesina2012] threshold $\sigma\sqrt{SC} < 1$.

```{r, echo = FALSE}
dat <- read.csv(file = "sim_results/C_1/random_all.csv");
dat <- dat[,-1];
```

To investigate the effect of $Var(\gamma)$ on system stability, I simulated random $M$ matrices at $\sigma = 0.4$ and $C = 1$ across $S$ ranging from 2-32. One million $M$ were simulated for each $S$, and the stability of $M$ was assessed given $\gamma = 1$ versus $\gamma \sim \mathcal{U}(0, 2)$. For all $S > 10$, I found that the number of stable random systems was higher given $Var(\gamma)$ than when $\gamma = 1$ (Fig. 3), and that the difference between the probabilities of observing a stable system increased with an increase in $S$; i.e., the potential for $Var(\gamma)$ to drive stability increased with system complexity. For the highest values of $S$, nearly all systems that were stable given $Var(\gamma)$ would not have been stable given $\gamma = 1$ (see Supplementary Information for full results). This suggests that the stability of large systems might be dependent upon variation in the response rate of their individual components, meaning that factors such as generation time (in ecological networks), transaction speed (in economic networks), or communication speed (in social networks) needs to be considered when investigating the stability of complex systems.

It is important to point out that $Var(\gamma)$ is not stabilising per se; that is, adding variation in $\gamma$ to a particular system $M$ does not necessarily increase the probability that the system will be stable (see Supplementary Information). Rather, systems that are observed to be stable are more likely to vary in $\gamma$, and for this $Var(\gamma)$ to be critical to their stability. This is caused by the shift in the distribution of eigenvalues that occurs by introducing $Var(\gamma)$ (Fig. 1b, 2b), which can sometimes result in all $\Re(\lambda) < 0$ but might also increase $\Re(\lambda)$ values. 

To further investigate the potential of $Var(\gamma)$ to be stabilising, I used a genetic algorithm (the space of possible $\gamma$ values was too large to search exhaustively [@Hamblin2013]; see Supplementary Information). For each of 40000 random $M$ ($\sigma = 0.4$, $C = 1$), the genetic algorithm initialised 1000 different sets of $\gamma \sim \mathcal{U}(0, 2)$ values of size $S$. Eigenanalysis was performed on $M$ using each set of $\gamma$ values, and the 20 sets with the lowest $\max\left(\Re(\lambda)\right)$ each produced 50 clonal offspring with subsequent mutation and crossover between the resulting new population of 1000 $\gamma$ sets. The genetic algorithm terminated if a stable $M$ was found, 20 generations occurred, or a convergence criteria of minimum fitness increase between generations was satisfied. Across $S = \{2, 3, ..., 39, 40\}$, sets of $\gamma$ values were found that resulted in stable systems with probabilities that were up to four orders of magnitude higher than when $\gamma = 1$ (see Supplementary Information), meaning that stability could often be achieved by manipulating $S$ $\gamma$ values rather than $S \times S$ $M$ elements. Hence, managing the response rates of system components in a targetted way can potentially facilitate the stabilisation of complex systems through a reduction in dimensionality. 

I have focused broadly on random complex systems, but it is also worthwhile to consider more restricted interactions such as those of specific ecological networks [@Allesina2012]. These include systems in which all interactions are negative (competitive networks), positive (mutualist networks), or $i$ and $j$ pairs have opposing signs (predator-prey networks). In general, competitive and mutualist networks tend to be destabilising, and predator-prey network tend to be stabilising [@Allesina2011]. When $Var(\gamma)$ is applied to each, the proportion of stable competitive and predator-prey networks increases, but the proportion of stable mutualist networks does not (see Supplementary Information). Additionally, when each component of $M$ is interpreted as a unique species and given a random intrinsic growth rate [@Dougoud2018], feasibility is not increased by $Var(\gamma)$, suggesting that variation in species generation time might be unlikely to drive stability in purely multi-species networks (see Supplementary Information).

My results show that complex systems are more likely to be stable when the response rates of system components vary. These results are broadly applicable to understanding stability of complex networks in the physical, life, and social sciences.

<!--- 

If more discussion is needed, then talk about relation to Jirsa and Ding 2004.

--->

**Acknowledgements:** I am supported by a Leverhulme Trust Early Career Fellowship (ECF-2016-376). Conversations with L. Bussi&#xe8;re and N. Bunnefeld, and comments from J. J. Cusack and I. L. Jones, improved the quality of this work. 


**References**

<div id="refs"></div>

\clearpage

```{r echo = FALSE}
S     <- 200;
C     <- 0.05;
sigma <- 0.4;
pr_st <- read.csv(file = "sim_results/bi_gamma/bi_pr_st.csv");
pr_st <- pr_st[,-1];
```

```{r, echo = FALSE}
A0 <- read.csv(file = "sim_results/bi_gamma/S200_A0.csv");
A0 <- as.matrix(A0[,-1]);
A1 <- read.csv(file = "sim_results/bi_gamma/S200_A1.csv");
A1 <- as.matrix(A1[,-1]);

A0_e   <- eigen(A0)$values;
A0_r   <- Re(A0_e);
A0_i   <- Im(A0_e);
A1_e   <- eigen(A1)$values;
A1_r   <- Re(A1_e);
A1_i   <- Im(A1_e);

A0_vm       <- A0;
diag(A0_vm) <- NA;
A0vec       <- as.vector(t(A0_vm));
A0vec       <- A0vec[is.na(A0vec) == FALSE];
A1_vm       <- A1;
diag(A1_vm) <- NA;
A1vec       <- as.vector(t(A1_vm));
A1vec       <- A1vec[is.na(A1vec) == FALSE];
fhalf       <- 1:(0.5*length(A1vec));
shalf       <- (0.5*length(A1vec)+1):length(A1vec);
pr_st       <- read.csv(file = "sim_results/bi_gamma/bi_pr_st.csv");
pr_st       <- pr_st[,-1];
```

**Figure 1: Example distribution of eigenvalues before (a) and after (b) separating a randomly generated complex system into fast ($\boldsymbol{\gamma} = 1.95$) and slow ($\boldsymbol{\gamma} = 0.05$) component response rates.** Each panel shows the same system where $S = 200$, $C = 0.05$, and $\sigma = 0.4$, and in each case $E[\gamma] = 1$ (i.e., only the distribution of $\gamma$ differs between panels).  **a.** Eigenvalues plotted when all $\gamma = 1$; distributions of points are uniformly distributed within the grey circle with a radius of $\sigma\sqrt{SC} =$ `r round(sqrt(200) * sd(A0vec), digits =3)` centred at -1 on the real axis. **b.** Eigenvalues plotted when half $\gamma = 1.95$ and half $\gamma = 0.05$; distributions of points can be partitioned into one large circle centred at $\gamma = -1.95$ and one small circle centred at $\gamma = -0.05$. In a, the maximum real eigenvalue $\max\left(\Re(\lambda)\right) =$ `r format(max(A0_r), scientific = FALSE)`, while in b $\max\left(\Re(\lambda)\right) =$ `r format(max(A1_r), scientific = FALSE)`, meaning that the complex system in b but not a is stable because in b $\max\left(\Re(\lambda)\right) < 0$. In 1 million randomly generated complex systems under the same parameter values, `r sum(pr_st[,1])` was stable when $\gamma = 1$ while `r sum(pr_st[,2])` were stable when $\gamma = \{1.95, 0.05\}$. Overall, complex systems that are separated into fast versus slow components tend to be more stable than otherwise identical systems with identical component response rates.

```{r, eval = TRUE, echo = FALSE, fig.height = 6, fig.width = 9}
par(mfrow = c(1, 2), mar = c(0.5, 0.5, 0.5, 0.5), oma = c(5, 5, 0, 0));
plot(A0_r, A0_i, xlim = c(-3.7, 0.3), ylim = c(-2, 2), pch = 4, cex = 0.7,
     xlab = "", ylab = "", cex.lab = 1.5, cex.axis = 1.5, asp = 1);
vl <- seq(from = 0, to = 2*pi, by = 0.001);
A0x0 <- sqrt(200) * sd(A0vec) * cos(vl) + mean(diag(A0));
A0y0 <- sqrt(200) * sd(A0vec) * sin(vl);
text(x = -3.5, y = 2.25, labels = "a", cex = 2);
points(x = A0x0, y = A0y0, type = "l", lwd = 3, col = "grey");
points(A0_r, A0_i, pch = 4, cex = 0.7);

plot(A1_r, A1_i, xlim = c(-3.7, 0.3), ylim = c(-2, 2), pch = 4, cex = 0.7,
     xlab = "", ylab = "", cex.lab = 1.5, cex.axis = 1.5, asp = 1, 
     col = "black", yaxt = "n");

vl <- seq(from = 0, to = 2*pi, by = 0.001);
A0x1a <- sqrt(100) * sd(A1vec[fhalf]) * cos(vl) + mean(diag(A1)[1:100]);
A0y1a <- sqrt(100) * sd(A1vec[fhalf]) * sin(vl);
points(x = A0x1a, y = A0y1a, type = "l", lwd = 3, col = "grey");
A0x1b <- sqrt(100) * sd(A1vec[shalf]) * cos(vl) + mean(diag(A1)[101:200]);
A0y1b <- sqrt(100) * sd(A1vec[shalf]) * sin(vl);
points(x = A0x1b, y = A0y1b, type = "l", lwd = 3, col = "grey");

points(A1_r[1:100], A1_i[1:100],pch = 4, cex = 0.7);   

text(x = -3.5, y = 2.25, labels = "b", cex = 2);
mtext(side = 1, "Real", outer = TRUE, line = 3, cex = 2);
mtext(side = 2, "Imaginary", outer = TRUE, line = 2.5, cex = 2);
```

\clearpage


```{r echo = FALSE}
S     <- 1000;
C     <- 1;
sigma <- 0.4;
```

```{r, echo = FALSE}
A_comp <- NULL;
A_dat  <- rnorm(n = 1000000, mean = 0, sd = 0.4);
A_mat  <- matrix(data = A_dat, nrow = 1000);
C_dat  <- rbinom(n = 1000 * 1000, size = 1, prob = 0.05);
C_mat  <- matrix(data = C_dat, nrow = 1000, ncol = 1000);
A_mat     <- A_mat * C_mat;
A_mat  <- species_interactions(A_mat, type = 0);
gammas <- runif(n = 1000, min = 0, max = 2);

mu_gam <- mean(gammas);
diag(A_mat) <- -1;
A1     <- gammas * A_mat;
A0     <- mu_gam * A_mat;
A0_e   <- eigen(A0)$values;
A0_r   <- Re(A0_e);
A0_i   <- Im(A0_e);
A1_e   <- eigen(A1)$values;
A1_r   <- Re(A1_e);
A1_i   <- Im(A1_e);

A0_vm       <- A0;
diag(A0_vm) <- NA;
A0vec       <- as.vector(A0_vm);
A0vec       <- A0vec[is.na(A0vec) == FALSE];
```

**Figure 2: Distributions of eigenvalues before (a) and after (b) introducing variation in component response rate ($\boldsymbol{\gamma}$) in complex systems.** Each panel show the same system where $S = 1000$, $C = 0.05$, and $\sigma = 0.4$. **a.** Eigenvalues plotted in the absence of $Var(\gamma)$ where $E[\gamma] = 1$, versus **b.** eigenvalues plotted given $\gamma \sim \mathcal{U}(0, 2)$, which increases the variance of interaction strengths ($\sigma^{2}$) but also creates a cluster of eigenvalues toward the distribution's centre (-1, 0). Black elipses in both panels show the circle centred on the distribution in panel a. Proportions of $\Re(\lambda) < 0$ are `r sum(A0_r < 0) / length(A0_r)` and `r sum(A1_r < 0) / length(A1_r)` for a and b, respectively.

```{r, eval = TRUE, echo = FALSE, fig.height = 6, fig.width = 9}
par(mfrow = c(1, 2), mar = c(0.5, 0.5, 0.5, 0.5), oma = c(5, 5, 0, 0));
plot(A0_r, A0_i, xlim = c(-6, 2.25), ylim = c(-5,4.25), pch = 4, cex = 0.7,
     xlab = "", ylab = "", cex.lab = 1.5, cex.axis = 1.5, asp = 1);
vl <- seq(from = 0, to = 2*pi, by = 0.001);
x0 <- sqrt(1000) * sd(A0vec) * cos(vl) + mean(diag(A0));
y0 <- sqrt(1000) * sd(A0vec) * sin(vl);
text(x = -15.5, y = 19, labels = "a", cex = 2);
points(x = x0, y = y0, type = "l", lwd = 3);
plot(A1_r, A1_i, xlim = c(-6, 2.25), ylim = c(-5,4.25), pch = 4, cex = 0.7,
     xlab = "", ylab = "", cex.lab = 1.5, cex.axis = 1.5, asp = 1, col = "red",
     yaxt = "n");
text(x = -15.5, y = 19, labels = "b", cex = 2);
points(x = x0, y = y0, type = "l", lwd = 3, lty = "solid");
mtext(side = 1, "Real", outer = TRUE, line = 3, cex = 2);
mtext(side = 2, "Imaginary", outer = TRUE, line = 2.5, cex = 2);
```

\clearpage


```{r, echo = FALSE}
dat <- read.csv(file = "sim_results/C_1/random_all.csv");
dat <- dat[,-1];
```

**Figure 3: Stability of large complex systems with and without variation in component response rate($\boldsymbol{\gamma}$).** The $\ln$ number of systems that are stable across different system sizes ($S$) given $C = 1$, and the proportion of systems in which variation in $\gamma$ is critical for system stability. For each $S$, 1 million complex systems are randomly generated. Stability of each complex system is tested given variation in $\gamma$ by randomly sampling $\gamma \sim \mathcal{U}(0, 2)$. Stability given $Var(\gamma)$ is then compared to stability in an otherwise identical system in which $\gamma = E[\mathcal{U}(0, 2)]$ for all components. Light and dark grey bars show the number of stable systems in the absence and presence of $Var(\gamma)$, respectively. The black line shows the proportion of systems that are stable when $Var(\gamma) > 0$, but would be unstable if $Var(\gamma) = 0$.

```{r, eval = TRUE, echo = FALSE, fig.width = 9, fig.height = 7}
dat <- read.csv(file = "sim_results/C_1/random_all.csv");
dat <- dat[,-1];
plot_stables(dat);
```

